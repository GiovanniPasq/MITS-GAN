{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPQpEA8UjJlWDm54xmQldSo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Install the CT-GAN Dependencies\n","NB: pytorch is required and it is installed by default in google colab"],"metadata":{"id":"37MF-NVe2t0c"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EUJuc21p2K6g","executionInfo":{"status":"ok","timestamp":1727888749707,"user_tz":-120,"elapsed":34049,"user":{"displayName":"Giovanni","userId":"18218532099836403290"}},"outputId":"0767f08c-e13d-4438-9174-f47d66c3c891"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n","Collecting scipy\n","  Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Collecting matplotlib\n","  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Collecting pandas\n","  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n","Collecting keras\n","  Downloading keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n","Collecting SimpleITK\n","  Downloading SimpleITK-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n","Collecting pydicom\n","  Downloading pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.8.1)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.12.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n","Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m119.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading keras-3.5.0-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading SimpleITK-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: SimpleITK, scipy, pydicom, pandas, matplotlib, keras\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.13.1\n","    Uninstalling scipy-1.13.1:\n","      Successfully uninstalled scipy-1.13.1\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 2.2.2\n","    Uninstalling pandas-2.2.2:\n","      Successfully uninstalled pandas-2.2.2\n","  Attempting uninstall: matplotlib\n","    Found existing installation: matplotlib 3.7.1\n","    Uninstalling matplotlib-3.7.1:\n","      Successfully uninstalled matplotlib-3.7.1\n","  Attempting uninstall: keras\n","    Found existing installation: keras 3.4.1\n","    Uninstalling keras-3.4.1:\n","      Successfully uninstalled keras-3.4.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.6.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\n","gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.14.1 which is incompatible.\n","google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed SimpleITK-2.4.0 keras-3.5.0 matplotlib-3.9.2 pandas-2.2.3 pydicom-3.0.1 scipy-1.14.1\n"]}],"source":["!pip install --upgrade scipy matplotlib pandas tensorflow keras SimpleITK pydicom"]},{"cell_type":"markdown","source":["Create a new folder Named MITS-GAN and put inside the following files/folders:<br>\n","\n","```\n","MITS-GAN\n","|\n","└───data/\n","│    └───ct_scan_1.raw\n","│    └───ct_scan_1.mhd\n","│    │        \n","│    |       ...\n","|    |\n","│    └───ct_scan_n.raw\n","│    └───ct_scan_n.mhd\n","|\n","└───models/\n","|     └───INJ\n","|     |    └───G_model_inj.h5\n","|     |    └───normalization.npy\n","|     |    └───equalization.pkl\n","|     |  \n","│     └───REM\n","│          └───G_model_rem.h5\n","|          └───normalization.npy\n","|          └───equalization.pkl\n","|\n","└───procedures/\n","│     └───attack_pipeline.py\n","|\n","└───utils/\n","|     └───dataloader.py\n","|     └───dicom_utils.py\n","|     └───equalizer.py\n","|     └───utils.py\n","|\n","│- config.py\n","│- discriminator.py\n","|- generator.py\n","|- scanDataset.py\n","|- train.py\n","```"],"metadata":{"id":"uplTsORd3Wo8"}},{"cell_type":"markdown","source":["Download the dataset and the pretrained model from the CT-GAN repo by contacting the authors and place them respectively inside the data and model folders. Run the training script below"],"metadata":{"id":"bSTc_p6F6M3S"}},{"cell_type":"code","source":["!python3 MITS-GAN/train.py"],"metadata":{"id":"UKoHyTw08Omd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727892601327,"user_tz":-120,"elapsed":1408384,"user":{"displayName":"Giovanni","userId":"18218532099836403290"}},"outputId":"4b042420-284c-4e81-b7b9-bff45c53da31"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Generator(\n","  (noisenet): Noisenet(\n","    (net_noise): Sequential(\n","      (0): Conv2d(1, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(2, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (4): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","      (6): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (7): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (8): ReLU(inplace=True)\n","      (9): Conv2d(4, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (10): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (11): ReLU(inplace=True)\n","      (12): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (13): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (14): ReLU(inplace=True)\n","    )\n","  )\n","  (main): Sequential(\n","    (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): residual_block(\n","      (main): Sequential(\n","        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (shortcut): Sequential()\n","    )\n","    (3): residual_block(\n","      (main): Sequential(\n","        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (shortcut): Sequential()\n","    )\n","    (4): residual_block(\n","      (main): Sequential(\n","        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (shortcut): Sequential()\n","    )\n","    (5): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n","    (6): Tanh()\n","  )\n",")\n","Discriminator(\n","  (main): Sequential(\n","    (0): Conv2d(1, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (2): Conv2d(1, 2, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (3): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (5): Conv2d(2, 4, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (6): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (8): Conv2d(4, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (9): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (11): Conv2d(8, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (12): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (13): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (14): Conv2d(8, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (15): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (16): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (17): Conv2d(8, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (18): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (19): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (20): Conv2d(8, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n","    (21): Sigmoid()\n","  )\n",")\n","2024-10-02 17:46:35.693206: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-10-02 17:46:35.713349: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-10-02 17:46:35.719493: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-10-02 17:46:35.734256: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-10-02 17:46:37.221947: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1727891199.086196   11806 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","I0000 00:00:1727891199.096890   11806 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","I0000 00:00:1727891199.097108   11806 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","===Init Tamperer===\n","Loading models\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n","I0000 00:00:1727891199.430892   11806 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","I0000 00:00:1727891199.431205   11806 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","I0000 00:00:1727891199.431396   11806 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","I0000 00:00:1727891199.441235   11806 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","I0000 00:00:1727891199.441449   11806 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-10-02 17:46:39.441613: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","I0000 00:00:1727891199.441687   11806 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-10-02 17:46:39.441876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13931 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","Loaded Injector Model\n","WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","Loaded Remover Model\n","Starting Training Loop...\n","Loading scan\n","===Removing Evidence===\n","Cutting out target region\n","Normalizing sample\n","Removing evidence\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1727891524.565732   11843 service.cc:146] XLA service 0x7afaf0004780 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","I0000 00:00:1727891524.565776   11843 service.cc:154]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2024-10-02 17:52:04.600867: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","2024-10-02 17:52:04.667918: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n","2024-10-02 17:52:05.277468: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 8.00GiB (8589934592 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","2024-10-02 17:52:05.278654: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 7.20GiB (7730940928 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","2024-10-02 17:52:05.279789: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 6.48GiB (6957846528 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","2024-10-02 17:52:05.281009: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 5.83GiB (6262061568 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","2024-10-02 17:52:05.281047: W external/local_tsl/tsl/framework/bfc_allocator.cc:363] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n","2024-10-02 17:52:05.284233: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 8.00GiB (8589934592 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","2024-10-02 17:52:05.285313: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 7.20GiB (7730940928 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","2024-10-02 17:52:05.286475: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 6.48GiB (6957846528 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","2024-10-02 17:52:05.287655: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 5.83GiB (6262061568 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","2024-10-02 17:52:05.287686: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2024-10-02 17:52:05.852252: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 8.00GiB (8589934592 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","2024-10-02 17:52:05.853443: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 7.20GiB (7730940928 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","2024-10-02 17:52:05.854623: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 6.48GiB (6957846528 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","2024-10-02 17:52:05.855821: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 5.83GiB (6262061568 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","I0000 00:00:1727891526.511121   11843 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Injecting Evidence===\n","Cutting out target region\n","Normalizing sample\n","Injecting evidence\n","2024-10-02 17:52:41.851948: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 22.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2024-10-02 17:52:41.915473: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 6.36GiB (6830730240 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","2024-10-02 17:52:41.916791: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 5.72GiB (6147657216 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","2024-10-02 17:52:41.916836: W external/local_tsl/tsl/framework/bfc_allocator.cc:363] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n","2024-10-02 17:52:42.061020: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 11.61GiB (12466585600 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","2024-10-02 17:52:42.064199: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 10.45GiB (11219927040 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","2024-10-02 17:52:42.066006: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 9.40GiB (10097934336 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","2024-10-02 17:52:42.067721: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 8.46GiB (9088140288 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","2024-10-02 17:52:42.068848: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 7.62GiB (8179325952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","2024-10-02 17:52:42.069957: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 6.86GiB (7361393152 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","2024-10-02 17:52:42.071505: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 6.17GiB (6625253888 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","2024-10-02 17:52:42.073535: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 5.55GiB (5962728448 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","2024-10-02 17:52:42.073571: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2024-10-02 17:52:42.364283: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 11.61GiB (12466585600 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","2024-10-02 17:52:42.366484: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 10.45GiB (11219927040 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","2024-10-02 17:52:42.368615: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 9.40GiB (10097934336 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","2024-10-02 17:52:42.370569: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 8.46GiB (9088140288 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","2024-10-02 17:52:42.372398: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 7.62GiB (8179325952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","2024-10-02 17:52:42.374318: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 6.86GiB (7361393152 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","2024-10-02 17:52:42.376168: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 6.17GiB (6625253888 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","2024-10-02 17:52:42.378172: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 5.55GiB (5962728448 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Removing Evidence===\n","Cutting out target region\n","Normalizing sample\n","Removing evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Injecting Evidence===\n","Cutting out target region\n","Normalizing sample\n","Injecting evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Removing Evidence===\n","Cutting out target region\n","Normalizing sample\n","Removing evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Injecting Evidence===\n","Cutting out target region\n","Normalizing sample\n","Injecting evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Removing Evidence===\n","Cutting out target region\n","Normalizing sample\n","Removing evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Injecting Evidence===\n","Cutting out target region\n","Normalizing sample\n","Injecting evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Removing Evidence===\n","Cutting out target region\n","Normalizing sample\n","Removing evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Injecting Evidence===\n","Cutting out target region\n","Normalizing sample\n","Injecting evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Removing Evidence===\n","Cutting out target region\n","Normalizing sample\n","Removing evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Injecting Evidence===\n","Cutting out target region\n","Normalizing sample\n","Injecting evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Removing Evidence===\n","Cutting out target region\n","Normalizing sample\n","Removing evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Injecting Evidence===\n","Cutting out target region\n","Normalizing sample\n","Injecting evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Removing Evidence===\n","Cutting out target region\n","Normalizing sample\n","Removing evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Injecting Evidence===\n","Cutting out target region\n","Normalizing sample\n","Injecting evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Removing Evidence===\n","Cutting out target region\n","Normalizing sample\n","Removing evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Injecting Evidence===\n","Cutting out target region\n","Normalizing sample\n","Injecting evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Removing Evidence===\n","Cutting out target region\n","Normalizing sample\n","Removing evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Injecting Evidence===\n","Cutting out target region\n","Normalizing sample\n","Injecting evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Removing Evidence===\n","Cutting out target region\n","Normalizing sample\n","Removing evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Injecting Evidence===\n","Cutting out target region\n","Normalizing sample\n","Injecting evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Removing Evidence===\n","Cutting out target region\n","Normalizing sample\n","Removing evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Injecting Evidence===\n","Cutting out target region\n","Normalizing sample\n","Injecting evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Removing Evidence===\n","Cutting out target region\n","Normalizing sample\n","Removing evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Injecting Evidence===\n","Cutting out target region\n","Normalizing sample\n","Injecting evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Removing Evidence===\n","Cutting out target region\n","Normalizing sample\n","Removing evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Injecting Evidence===\n","Cutting out target region\n","Normalizing sample\n","Injecting evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Removing Evidence===\n","Cutting out target region\n","Normalizing sample\n","Removing evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Injecting Evidence===\n","Cutting out target region\n","Normalizing sample\n","Injecting evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Removing Evidence===\n","Cutting out target region\n","Normalizing sample\n","Removing evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","Loading scan\n","===Injecting Evidence===\n","Cutting out target region\n","Normalizing sample\n","Injecting evidence\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","De-normalizing sample\n","Pasting sample into scan\n","Adding noise touch-ups...\n","touch-ups complete\n","^C\n"]}]}]}